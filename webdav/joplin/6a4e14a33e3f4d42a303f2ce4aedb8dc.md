text-embeddings-inference

https://github.com/huggingface/text-embeddings-inference

tweaked

model=BAAI/bge-small-en-v1.5
revision=refs/pr/3
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run  -p 8787:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:latest --model-id $model --revision $revision

{ "input": "tell me your name", "model": "null", "user": "null" }


curl 127.0.0.1:8080/embed \
    -X POST \
    -d '{"inputs":"What is Deep Learning?"}' \
    -H 'Content-Type: application/json'
	
	curl 127.0.0.1:8787/openai \
    -X POST \
    -d '{ "input": "tell me your name", "model": "null", "user": "null" }' \
    -H 'Content-Type: application/json'

id: 6a4e14a33e3f4d42a303f2ce4aedb8dc
parent_id: 2943428fa88c4f4c8a8ab3dce9498c00
created_time: 2023-10-14T16:10:42.370Z
updated_time: 2023-10-14T21:53:15.739Z
is_conflict: 0
latitude: 44.14941000
longitude: 10.38761333
altitude: 361.4000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin
source_application: net.cozic.joplin-mobile
application_data: 
order: 1697299842293
user_created_time: 2023-10-14T16:10:42.370Z
user_updated_time: 2023-10-14T21:53:15.739Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
type_: 1