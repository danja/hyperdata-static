<!DOCTYPE html>
<html>

<head>
    <title>Blog - Another Interim Blog</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width">
    <link rel="stylesheet" type="text/css" href="/css/style.css">
</head>

<body id="{{ slug }}">
    <script id="replace_with_navbar" src="/share/nav.js"></script>
    <br />
    <br />
    <br />
    <em>Interim blog setup, rough notes being dumped here at the moment - I'll tidy once I get to a milestone. And sorry
        about the layout, that'll probably take even longer to get around to... #TODO</em>
    <br />
    <br />
    <main>
        <h1>Blog</h1>
<article>
    <h2><a href="/blog/todo/">Blog TODO</a></h2>
    <p class="meta">Published on 2050-01-01 by <b>@danja</b></p>

    <p class="content">
        <p><em>far in the future</em></p>
<p>I rather like this mode of blogging, type markdown into VSCode, <code>makesite.py</code> converts/formats it, use git (in a script) to transfer to server.</p>
<p>Three things to do soonish :</p>
<ul>
<li>layout : make it prettier &amp; more navigable, maybe make it 2 or 3 column for index etc.</li>
<li>add a forward-chrono view from a given post, makes more sense with the things like continuing notes (can always make it more sophisticated via SPARQL store)</li>
<li>add support for multiple topic-specific blogs</li>
<li>add a directory treewalker to send the content etc. up to my SPARQL store (I've a feeling I've done this before in Python, very straightforward - it's be quicker to do afresh, with the help of <code>sparqlwrapper</code> and ChatGPT)</li>
</ul>
<p>I reckon I'll split <code>makesite.py</code> up, modularise a bit. Even if I move to all SPARQL-backed for the blog, it's bound to be useful somewhere.</p>
<p>Things for later :</p>
<h4>Turtle plugin for markdown</h4>
<p>similar to https://github.com/ozekik/markdown-ld</p>
<p>https://raw.githubusercontent.com/ozekik/markdown-ld/master/examples/foaf.md</p>
<p>Requirements :</p>
<ol>
<li>independent of, but compatible with existing markdown tools</li>
<li>extensible, reasonably modular</li>
<li>block identifier &amp; delimiters</li>
<li>useful defaults, easily overriden</li>
</ol>
<p>For most of 1 &amp; 2, make it easy to put in pipeline, something like :</p>
<p>markdown, other = mx(markdown_with_extensions)</p>
<p>for 3, maybe :</p>
<p>mx:turtle
'''</p>
<pre><code>&lt;this&gt; a x:That.
</code></pre>
<p>For 4, for starters I'd probably be good to had some standard prefixes as default, added by the processor, which could be overriden :</p>
<p>mx:turtle
mx:prefixes
'''</p>
<pre><code>prefix ...

&lt;this&gt; a x:That.
</code></pre>
<p>'''</p>
<pre><code class="language-Reminder">&gt;&gt;&gt; pair = (1, 2)
&gt;&gt;&gt; pair
(1, 2)
&gt;&gt;&gt; x, y = pair
&gt;&gt;&gt; x
1
&gt;&gt;&gt; y
2

&gt;&gt;&gt; pair[0]
1
&gt;&gt;&gt; pair[
</code></pre>
<p>Markdown Extension Vocab, mx:</p>
&nbsp;
        <!-- a class="more" href="/blog/todo/">...</a -->
    </p>
    <!--
<p class="summary">
far in the future I rather like this mode of blogging, type markdown into VSCode, makesite.py converts/formats it, use git (in a script) to transfer&nbsp;<a class="more" href="/blog/todo/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/todo/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-06/">llama_index SPARQL Notes 06</a></h2>
    <p class="meta">Published on 2023-09-01 by <b>@danja</b></p>

    <p class="content">
        <p>grr, forgot again,</p>
<p><strong>sudo /usr/local/nebula/scripts/nebula.service start all</strong></p>
<p>So far <code>nebula-rdf-dump.py</code> is making quasi-Turtle triples from the NebulaGraph data. If I provide some namespace prefixes that'll make it proper.
<code>er</code> for my minimal Entity-Relationship vocab, use the <code>base</code> to complete the instance data URIs.</p>
<p>Easy one, prepend it with :</p>
<pre><code>@prefix er: &lt;http://purl.org/stuff/er#&gt; .
@base &lt;http://purl.org/stuff/data&gt; .
</code></pre>
<p>Using f formatting in the code, run...</p>
<p>Check :</p>
<ul>
<li>rapper -c -i turtle guardians.ttl</li>
</ul>
<pre><code>rapper: Parsing URI file:///home/danny/AI/nlp/GraphRAG/nebula-sparql-utils/guardians.ttl with parser turtle
rapper: Parsing returned 2380 triples
</code></pre>
<p>Good-o.</p>
<p>Now to figure out the SPARQL to pust the stuff to the store.</p>
<p>Different prefix syntax, https://www.w3.org/TR/sparql11-query/#syntaxTerms</p>
<pre><code>BASE &lt;http://purl.org/stuff/data&gt;
PREFIX er:  &lt;http://purl.org/stuff/er#&gt;
</code></pre>
<p>What queries are needed?</p>
<p>https://www.w3.org/TR/sparql11-update</p>
<pre><code>CREATE ( SILENT )? GRAPH IRIref

DROP  ( SILENT )? (GRAPH IRIref | DEFAULT | NAMED | ALL )

INSERT DATA  QuadData
</code></pre>
<blockquote>
<p>where QuadData are formed by TriplesTemplates, i.e., sets of triple patterns, optionally wrapped into a GRAPH block.</p>
</blockquote>
<p>Ok, so here I guess an update call for :</p>
<pre><code>CREATE GRAPH &lt;http://purl.org/stuff/guardians&gt;
</code></pre>
<pre><code>{prefixes}
INSERT DATA {
    GRAPH &lt;http://purl.org/stuff/guardians&gt;
       { {triples} } }
</code></pre>
<p>ew, need to escape {} ... nah, less thought needed to concatenate with +</p>
<p>Good-oh, sparqlwrapper has an update example https://sparqlwrapper.readthedocs.io/en/latest/main.html#sparql-update-example (with auth)</p>
<pre><code>danny@danny-desktop:~/AI/nlp/GraphRAG/nebula-sparql-utils$ python nebula-rdf-dump.py
Update succeeded

Update succeeded
</code></pre>
<p>Looking good so far...check data at</p>
<p>https://fuseki.hyperdata.it/#/dataset/llama_index-test/query</p>
<pre><code>SELECT ?s ?p ?o WHERE {
    GRAPH &lt;http://purl.org/stuff/guardians&gt; {
            ?s ?p ?o
        }
}
LIMIT 50
</code></pre>
<p>Nothing!!!</p>
<p>Tried the SPARQL as dumped to file, then SELECT as above - looks fine.</p>
<pre><code>DROP GRAPH &lt;http://purl.org/stuff/guardians&gt;
</code></pre>
<p>check code around sparqlwrapper...</p>
<p>Hmm, can you reuse clients (create graph &amp; insert)? Apparenty not. Added code to make a new one - it worked!</p>
<p><strong>yardstone reached!</strong></p>
<p>Tired, but looking at next steps -</p>
<pre><code>from llama_index.storage.storage_context import StorageContext
from llama_index.graph_stores import NebulaGraphStore

...

%pip install nebula3-python ipython-ngql

os.environ['NEBULA_USER'] = &quot;root&quot;
os.environ['NEBULA_PASSWORD'] = &quot;nebula&quot; # default password
os.environ['NEBULA_ADDRESS'] = &quot;127.0.0.1:9669&quot; # assumed we have NebulaGraph installed locally

space_name = &quot;guardians&quot;
edge_types, rel_prop_names = [&quot;relationship&quot;], [&quot;relationship&quot;] # default, could be omit if create from an empty kg
tags = [&quot;entity&quot;] # default, could be omit if create from an empty kg

graph_store = NebulaGraphStore(
    space_name=space_name,
    edge_types=edge_types,
    rel_prop_names=rel_prop_names,
    tags=tags,
)
storage_context = StorageContext.from_defaults(graph_store=graph_store)
</code></pre>
<p>Looks like most of what StorageContext does is done through the graph store implementations, eg. SimpleGraphStore</p>
<p>Ok, I reckon next, back to putting tracer logging in NebulaGraphStore</p>
<ol>
<li>pull out a bit of code from Notebook that uses <code>nebulagraphstore.py</code> but not the OpenAI API</li>
<li>make sure it works!</li>
<li>point python at my dev llama_index</li>
<li>add logging points to dev llama_index <code>nebulagraphstore.py</code></li>
</ol>
<p>currently at :</p>
<p>~/.local/lib/python3.11/site-packages/llama_index</p>
<p>noo...that has a single subdir <code>readers</code></p>
<ul>
<li>locate document_summary.py
/home/danny/.local/pipx/venvs/llama-index/lib/python3.11/site-packages/llama_index/data_structs/document_summary.py</li>
</ul>
<p>Ok, this may or may not work - a symlink</p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-06/">...</a -->
    </p>
    <!--
<p class="summary">
grr, forgot again, sudo /usr/local/nebula/scripts/nebula.service start all So far nebula-rdf-dump.py is making quasi-Turtle triples from the NebulaGraph data. If I provide some namespace prefixes that'll&nbsp;<a class="more" href="/blog/llama-sparql-06/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-06/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-05/">llama_index SPARQL Notes 05</a></h2>
    <p class="meta">Published on 2023-08-31 by <b>@danja</b></p>

    <p class="content">
        <p>Grr...next admin session I must set up systemd</p>
<p><strong>sudo /usr/local/nebula/scripts/nebula.service start all</strong></p>
<p>for ChatGPT :</p>
<pre><code>I'd like a function to remove duplicates from a Python json structure. For example, give the following :
[
{'s': 'production on Vol.3', 'p': 'was put on hold until', 'o': 'February 2021'
},
{'s': 'production on Vol.3', 'p': 'put on hold until', 'o': 'February 2021'
},
{'s': 'production on Vol.3', 'p': 'was put on hold until', 'o': 'February 2021'
}
]
the function should return :
[
{'s': 'production on Vol.3', 'p': 'was put on hold until', 'o': 'February 2021'
},
{'s': 'production on Vol.3', 'p': 'put on hold until', 'o': 'February 2021'
}
]
</code></pre>
<p>It got it right first time!</p>
<p>So, next to flip this JSON into RDF/SPARQL.</p>
<p>Not 100% sure, but I don't think I actually need the <code>extract_entities</code> function, anything useful will also appear in <code>extract_entities</code> and the types/roles are implied by the triplets.</p>
<p><strong>sanitize</strong></p>
<p><code>def escape_for_rdf(input_str)</code> - thank you ChatGPT.</p>
<p>Given the following JSON, how would I retrieve the values of s, p, o?
[
{'s': &quot;Industrial Light &amp; Magic's StageCraft&quot;, 'p': 'was developed for', 'o': 'Disney+ Star Wars series The Mandalorian'
}
]</p>
<p>took a little backwards &amp; forwards, but we got there.</p>
<p>I'm really not sure what level of granularity will eventually be needed, for big lumps of data something else from the <a href="https://www.w3.org/TR/sparql11-http-rdf-update/">SPARQL Protocol</a> would probably be better (like a full-on HTTP PUT). Per-triple DELETE/INSERT might be desirable elsewhere. But here it shouldn't get too big, the INSERT approach <em>should</em> work, and would also work per-triple.</p>
<p>The NebulaGraph notion of a Space appears very similar to RDF/SPARQL Named Graphs, so I'll go with that (more information, and things can get messy doing everything in the default graph).</p>
<p>This is what I came up with the other day :</p>
<pre><code># Simple Entity-Relation

@base &lt;http://purl.org/stuff/data&gt; .
@prefix er: &lt;http://purl.org/stuff/er&gt; .

&lt;#T123&gt; a er:Triplet ;
er:id &quot;#T123&quot; ;
er:subject &lt;#E123&gt; ;
er:property &lt;#R456&gt; ;
er:object &lt;#E567&gt; .

&lt;#E123&gt; a er:Entity ;
er:value &quot;one&quot; .

&lt;#R456&gt; a er:Relationship ;
er:value &quot;two&quot; .

&lt;#E567&gt; a er:Entity ;
er:value &quot;three&quot; .
</code></pre>
<p>I opted for URL-named resources rather than blank nodes or other IRI because soon it may help with sanity-checking, further down the line the potential for HTTP retrieval is nice to have. There are a lot of annotation/meta triples that could be added, but I reckon this is about the minimum necessary to fulfil the <em>Wey Gu's Notebook with SPARQL</em> use case.</p>
<p>I guess I need a fragment ID generator. Suboptimal but so it's not too hard on the eyes for now, I'll got with alpha(capitals)-numeric. How many chars?</p>
<p>Please write a function to generate a random 4-character string using only numeric characters and capital letters.</p>
<p>Ok.</p>
<p>Need to keep identity of entities/relationships. I'm not sure what should happen if the same string is pulled out more than once as entity and/or relationship from different contexts. Should they have different IDs (URLs)? I don't fancy a deep dive into llama_index structures right now, I'll wait for someone to tell me. Whatever, giving identical strings the same URL shouldn't make a huge difference either way.</p>
<p>Strings appearing both in the role of Relationship &amp; Entity might also be thinking about. But again, for now, no big deal.</p>
<p>Ran current version -</p>
<pre><code>                        &lt;#THKOE&gt; a er:Triplet ;
                                er:subject &lt;#EK8WH&gt; ;
                                er:property &lt;#RJSJV&gt; ;
                                er:object &lt;#ELD8T&gt; .

                        &lt;#EK8WH&gt; a er:Entity ;
                                er:value &quot;Vol.3&quot; .

                        &lt;#RJSJV&gt; a er:Relationship ;
                                er:value &quot;is the first MCU film to feature&quot; .

                        &lt;#ELD8T&gt; a er:Entity ;
                                er:value &quot;the word  fuck  uncensored&quot; .
</code></pre>
<p>Progress!</p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-05/">...</a -->
    </p>
    <!--
<p class="summary">
Grr...next admin session I must set up systemd sudo /usr/local/nebula/scripts/nebula.service start all for ChatGPT : I'd like a function to remove duplicates from a Python&nbsp;<a class="more" href="/blog/llama-sparql-05/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-05/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-04/">llama_index SPARQL Notes 04</a></h2>
    <p class="meta">Published on 2023-08-30 by <b>@danja</b></p>

    <p class="content">
        <p>Continuing from <a href="2023-08-29-llama-sparql-03">yesterday</a> on getting data from a NebulaGraph store and putting it into a SPARQL store.</p>
<p>I was able to get a condensed JSON rendition of the Entity data from NebulaGraph, now to do the same with Relationships</p>
<pre><code>USE guardians;
MATCH (src:entity)-[e:relationship]-&gt;(dst:entity)
RETURN src, e, dst
LIMIT 10;
</code></pre>
<p>ChatGPT time -</p>
<blockquote>
<p>The task will be to create a function to extend an existing Python file. The purpose of this is to take data of a specific shape from a NebulaGraph DB via the nebula3 API and save it in a condensed form as JSON text. I will first give you the nGQL statements that were used to create the NebulaGraph space, then upload a the file, then describe the function I would like to add to it. Here are the nGQL statements :</p>
</blockquote>
<pre><code>CREATE SPACE guardians(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);
:sleep 10;
USE guardians;
CREATE TAG entity(name string);
CREATE EDGE relationship(relationship string);
:sleep 10;
CREATE TAG INDEX entity_index ON entity(name(256));
</code></pre>
<blockquote>
<p>In the file there is the API call :
resp = client.execute_json('MATCH (v:entity) RETURN v')
I will add :
resp_rel = client.execute_json('MATCH (src:entity)-[e:relationship]-&gt;(dst:entity) RETURN src, e, dst')
json_rel_str = resp_rel.decode('utf-8')
Please write a function extract_relationships(json_rel_str) following the pattern of extract_entities(json_data)</p>
</blockquote>
<p>What it gave me looks close, but the output was :</p>
<pre><code>    {'src': 'N/A', 'relationship': 'N/A', 'dst': 'N/A'
    },
    {'src': 'N/A', 'relationship': 'N/A', 'dst': 'N/A'
    },
...
</code></pre>
<p>I will upload a file containing a single result from the database. I would like the data extracted from this by the function extract_relationships to be:
[{&quot;src&quot;: &quot;production on Vol.3&quot;, &quot;rel&quot;: &quot;relationship&quot;, &quot;dst&quot;: &quot;February 2021&quot;}]
please modify the function accordingly</p>
<blockquote>
<p>ChatGPT
Finished working
Show work
It appears that I forgot to request the file upload. Could you please upload the file containing a single result from the database? This will help me modify the extract_relationships function to meet your requirements.</p>
</blockquote>
<p>We went around in circles a lot. ChatGPT's mapping was repeatedly out, I hadn't looked closely neough at the NebulaGraph results.</p>
<p>But finally I ran with :</p>
<pre><code>resp_rel = client.execute_json(
    'MATCH (src:entity)-[e:relationship]-&gt;(dst:entity) RETURN src, e, dst' LIMIT 1)
</code></pre>
<p>effectively <em>make it like</em> :</p>
<pre><code>[{&quot;s&quot;: &quot;production on Vol.3&quot;, &quot;p&quot;: &quot;was put on hold until&quot;, &quot;o&quot;: &quot;February 2021&quot;}]
</code></pre>
<p>Yes! There are a lot of duplicates in the output but I'll just hack that for now. But I think I've done the unfmiliar bits now, the RDF/SPARQL side should be straightforward from here.</p>
<p>Enough for today.</p>
<p><strong>This would probably have been much easier with JSON-LD. But since I started down this path...</strong></p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-04/">...</a -->
    </p>
    <!--
<p class="summary">
Continuing from yesterday on getting data from a NebulaGraph store and putting it into a SPARQL store. I was able to get a condensed JSON&nbsp;<a class="more" href="/blog/llama-sparql-04/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-04/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/ejabberd/">ejabberd Notes</a></h2>
    <p class="meta">Published on 2023-08-30 by <b>@danja</b></p>

    <p class="content">
        <p>danbri mentioned XMPP (for ChatGPT) yesterday, it appears I have ejabberd installed. Is it running?</p>
<p>Browser-based client :</p>
<p>https://conversejs.org/docs/html/quickstart.html</p>
<blockquote>
<p>Pro-tip, if you just want to quickly test things locally, you can run make serve inside a checkout of the Converse repo. Converse is then hosted at http://localhost:8000</p>
</blockquote>
<ul>
<li>git clone https://github.com/conversejs/converse.js.git</li>
<li>cd converse.js</li>
<li>make serve <em>(it does an npm install of stuff)</em></li>
</ul>
<p>} from '../../../node_modules/lit/html.js';
// } from './html.js'; danny</p>
<p>cp node_modules/lit/html.js src/headless/utils/</p>
<p>grr, hateful thing, given up.</p>
<ul>
<li>yes | rm -r converse.js</li>
</ul>
<p>Installed gajim (via synaptic) instead</p>
<p>no immediate joy (where to cofig servers?)</p>
<p>Installed pidgin</p>
<p>isn't connecting - the Enabled box for the account unchecks itself</p>
<ul>
<li>systemctl restart ejabberd</li>
<li>systemctl status ejabberd</li>
</ul>
<pre><code>Active: activating (start) since Wed 2023-08-30 11:13:37 UTC; 3min 22s ago
...
Aug 30 11:15:27 localhost sh[443214]: 2023-08-30 11:15:27.334892+00:00 [error] Cannot ping watchdog: {badmatch,{error,eacces}}
</code></pre>
<p>looks like the install is old, I think done from .deb
So,</p>
<ul>
<li>wget https://github.com/processone/ejabberd/releases/download/23.04/ejabberd_23.04-1_amd64.deb</li>
<li>dpkg -i ejabberd_23.04-1_amd64.deb</li>
</ul>
<pre><code>Unpacking ejabberd (23.04-1) over (21.12-1) ...
...
Could not execute systemctl:  at /usr/bin/deb-systemd-invoke line 142.
</code></pre>
<p>Oops!</p>
<ul>
<li>systemctl stop ejabberd</li>
<li>systemctl start ejabberd</li>
<li>systemctl status ejabberd</li>
</ul>
<p>Grrr, <code>Cannot ping watchdog</code> again.</p>
<p>Google...</p>
<p>https://askubuntu.com/questions/1411679/ubuntu-22-04-ejabberd-apparmour-profile-broken</p>
<pre><code>Description=A distributed, fault-tolerant Jabber/XMPP server
Documentation=https://www.process-one.net/en/ejabberd/docs/
After=epmd.service network.target
Requires=epmd.service

[Service]
Type=forking
User=ejabberd
Group=ejabberd
LimitNOFILE=65536
Restart=on-failure
RestartSec=5
ExecStart=/bin/sh -c '/usr/sbin/ejabberdctl start &amp;&amp; /usr/sbin/ejabberdctl started'
ExecStop=/bin/sh -c '/usr/sbin/ejabberdctl stop &amp;&amp; /usr/sbin/ejabberdctl stopped'
ExecReload=/bin/sh -c '/usr/sbin/ejabberdctl reload_config'
PrivateTmp=true
ProtectHome=true
ProtectSystem=full
TimeoutSec=300

[Install]
WantedBy=multi-user.target
</code></pre>
<ul>
<li>mv ejabberd.service ejabberd_old_service</li>
<li>nano, paste the above</li>
<li>systemctl daemon-reload</li>
<li>systemctl restart ejabberd</li>
</ul>
<p><code>Active: active (running) since Wed 2023-08-30 11:47:14 UTC; 33s ago</code></p>
<p>Yay!</p>
<p>From pidgin :</p>
<pre><code>danja@hyperdata.it/ disconnected
Host Unknown
</code></pre>
<p>Port problem? Whatever, enough of that for now.</p>
<hr />
<p>Hah! The second I returned to Lemmy setup, I saw mynotes from when I installed ejabberd last time :</p>
<p><strong>2022-10-27</strong></p>
<pre><code>installed ejabberd

Creating config file /etc/default/ejabberd with new version

Creating config file /etc/ejabberd/ejabberd.yml with new version
Created symlink /etc/systemd/system/multi-user.target.wants/ejabberd.service → /
lib/systemd/system/ejabberd.service.

admin@hyperdata.it

/etc/ejabberd/ejabberd.yml

ejabberdctl reload_config

ejabberdctl register admin hyperdata.it [password]

https://hyperdata.it:5280/admin/

ejabberdctl register danny hyperdata.it [password]
ejabberdctl register device hyperdata.it [password]
ejabberdctl register marinella hyperdata.it [password]

locally
mosquitto_sub -u danny@hyperdata.it -P  [password] -t &quot;test/1&quot; -d -v
new terminal
mosquitto_pub -u device@hyperdata.it -P  [password] -t &quot;test/1&quot; -d -m &quot;ABC&quot;
</code></pre>
<p>...Whatever, enough of that for now.</p>
&nbsp;
        <!-- a class="more" href="/blog/ejabberd/">...</a -->
    </p>
    <!--
<p class="summary">
danbri mentioned XMPP (for ChatGPT) yesterday, it appears I have ejabberd installed. Is it running? Browser-based client : https://conversejs.org/docs/html/quickstart.html Pro-tip, if you just want to&nbsp;<a class="more" href="/blog/ejabberd/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/ejabberd/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-03/">llama_index SPARQL Notes 03</a></h2>
    <p class="meta">Published on 2023-08-29 by <b>@danja</b></p>

    <p class="content">
        <h3>Today</h3>
<p><em>I'm down to $0.23 OpenAI API credit, so until I next have $ need to look at things that don't need it. <code>sparql.py</code> doesn't in itself need the OpenAI API, but a SPARQLy version of Wey Gu's Notebook is my target functional E2E test.</em></p>
<blockquote>
<p>I still have NebulaGraph data generated from Wey's Notebook. I can use nebula-python to pull out data from there, RDFLib to build RDF, sparqlwrapper to push to store. The SPARQL needed will be essentially the same as for <code>sparql.py</code>. Also NebulaGraph &lt;=&gt; RDF utils would be nice to have (may already exist, but I'll pretend I didn't consider that, need to inform myself).</p>
</blockquote>
<p>Then -</p>
<ul>
<li>have a look around <em>3 Create VectorStoreIndex for RAG</em> in Notebook</li>
<li>put the INSERT &amp; SELECT queries inside sparql.py</li>
<li>...</li>
</ul>
<hr />
<p><strong>MOVE PATH FROM llama_index INSTALLED TO DEV TREE</strong></p>
<p><strong>sudo /usr/local/nebula/scripts/nebula.service start all</strong></p>
<p>Started with :</p>
<p><code>resp = client.execute_json('MATCH (v:entity) RETURN v')</code></p>
<p>After converting this to string there were character encoding errors. Should really be investigated properly, but for now I'll just go with some quick &amp; dirty sanitization (Valid RDF literals will probably need <em>something</em> anyhow).</p>
<p><code>json_str = resp.decode('utf-8')</code> appears to have fixed the encoding issues.</p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-03/">...</a -->
    </p>
    <!--
<p class="summary">
Today I'm down to $0.23 OpenAI API credit, so until I next have $ need to look at things that don't need it. sparql.py doesn't&nbsp;<a class="more" href="/blog/llama-sparql-03/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-03/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/lemmy/">Lemmy</a></h2>
    <p class="meta">Published on 2023-08-29 by <b>@danja</b></p>

    <p class="content">
        <p>https://github.com/LemmyNet</p>
<p>recommends <a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">Ansible</a></p>
<p>I opted for the full version -</p>
<ul>
<li>pipx install --include-deps ansible</li>
</ul>
<p><em>ew</em>, initial bits painful, found the docs confusing, maybe assume more prior knowledge than I have (only used Docker a bit, have never used Ansible). More worrying, I haven't a clue what it's stuck on my server.</p>
<p><strong>2023-08-30</strong></p>
<p>The Ansible thing did look like it'd mostly run ok, but things definitely fell apart around <code>nginx</code>. Very likely cause being host:port clash, as I already have an Apache server in front on hyperdata.it/127.0.0.1 :80 and :443</p>
<p>https://www.geeksforgeeks.org/changing-nginx-port-in-linux/</p>
<p>I changed the default config yesterday, but just looked again, there's actually :</p>
<pre><code>/etc/nginx/sites-available/default
/etc/nginx/sites-available/hyperdata.it.conf
/etc/nginx/sites-enabled/default
/etc/nginx/sites-enabled/hyperdata.it.conf
</code></pre>
<p>So I've deleted the <code>/etc/nginx/sites-enabled/default</code> symlink and changed <code>hyperdata.it.conf</code> to use <strong>port 8421</strong></p>
<ul>
<li>sudo systemctl restart nginx.service</li>
<li><em>failed</em></li>
<li>systemctl status nginx.service | less</li>
<li>nginx: [emerg] bind() to 0.0.0.0:443 failed</li>
</ul>
<p>I'm pretty sure I don't need https/443 on nginx, I've got Apache doing that, is proxying to Fuseki etc on plain http on different ports. So I've deleted that section from <code>hyperdata.it.conf</code></p>
<ul>
<li>systemctl restart nginx.service</li>
<li>systemctl status nginx.service</li>
</ul>
<blockquote>
<p>Active: active (running) since Wed 2023-08-30 09:27:02 UTC; 12s ago</p>
</blockquote>
<p>Yay!</p>
<p>Hmm. http://hyperdata.it:8421 just redirects to https://hyperdata.it/</p>
<p>On server,</p>
<ul>
<li>apt install lynx</li>
<li>lynx http://127.0.0.1:8421</li>
</ul>
<blockquote>
<p>Currently reorganising the server. I'll put my FOAF/Solid here soon, for now my contact details should be at :
https://hyperdata.it/
note to self : this is /opt/lampp/htdocs/profile/index.html</p>
</blockquote>
<p>Aha! That's my placeholder for <code>https://danny.ayers.name/</code>, configured in Apache.</p>
<p>Where are my notes on Apache setup..?</p>
<p><code>~/HKMS/server-setup/</code> apparently - TODO make that easier to find</p>
<p><strong>distraction</strong> danbri mentioned XMPP (for ChatGPT) yesterday, it appears I have ejabberd installed. Is it running? see <a href="ejabberd">ejabberd Notes</a></p>
<p>https://lemmy.hyperdata.it</p>
<p>http://lemmy.hyperdata.it
http://lemmy.hyperdata.it:8421
https://lemmy.hyperdata.it:8421
http://hyperdata.it:8421
https://hyperdata.it:8421</p>
<p>lynx http://127.0.0.1:8421</p>
<pre><code>root@localhost:~/temp# wget http://127.0.0.1:8421
--2023-09-01 11:19:35--  http://127.0.0.1:8421/
Connecting to 127.0.0.1:8421... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://127.0.0.1/ [following]
--2023-09-01 11:19:35--  https://127.0.0.1/
Connecting to 127.0.0.1:443... connected.
    ERROR: certificate common name ‘danny.ayers.name’ doesn't match requested host name ‘127.0.0.1’.
To connect to 127.0.0.1 insecurely, use `--no-check-certificate'.
</code></pre>
<p>The only 301 that looked relevant was in :</p>
<p>nano /etc/nginx/sites-available/hyperdata.it.conf</p>
<p>so I removed that block</p>
<p>systemctl restart nginx.service</p>
<p>https://lemmy.hyperdata.it/ seems to redirect to http://lemmy.hyperdata.it/, nginx starter page.</p>
<p>That redirect was needed!</p>
<p>put it back, random longshot, removed (shouldn't be needed after Apache..?):</p>
<pre><code>    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }
</code></pre>
<p>in /var/log/nginx/access.log</p>
<pre><code>127.0.0.1 - - [01/Sep/2023:11:31:41 +0000] &quot;GET / HTTP/1.1&quot; 301 162 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36&quot;
</code></pre>
<p>It looks like it's getting that far, but the lemmy bit isn't doing anything</p>
<p>https://join-lemmy.org/docs/administration/troubleshooting.html</p>
<p>root@localhost:/home/hmks-apps/lemmy/hyperdata.it# docker-compose logs -f lemmy</p>
<pre><code>...
lemmy_1     | 	Is the server running on host &quot;postgres&quot; (172.18.0.3) and accepting
lemmy_1     | 	TCP/IP connections on port 5432?
...
</code></pre>
<p>I was in the middle of typing a message to ask for help on r/lemmy, when something occurred to me. Maybe Ansible doesn't do the external services. It's plausible that I'd already installed nginx, Ansible just added a config. But postgres, pictrs (?), the smpt service..?</p>
<p>sudo apt install postgresql</p>
<blockquote>
<p>The postgresql service is an &quot;umbrella&quot; service whose purpose is to start or stop the services named postgresql@version-instance which are the actual services that you are interested in. To get the statuses of these, run sudo systemctl status 'postgresql*'</p>
</blockquote>
<p>a PostgreSQL Cluster is running...</p>
<p>https://www3.ntu.edu.sg/home/ehchua/programming/sql/PostgreSQL_GetStarted.html</p>
<p>initial client access :</p>
<ul>
<li>sudo -u postgres psql</li>
<li>\l (list DBs)</li>
</ul>
<p>there is a DB postgres, owner postgres</p>
<p>wait, https://github.com/LemmyNet/lemmy/issues/1847</p>
<ul>
<li>root@localhost:/home/hmks-apps/lemmy/hyperdata.it# docker ps</li>
</ul>
<p>postgres was already running under docker :</p>
<ul>
<li>docker-compose exec postgres psql -U lemmy</li>
</ul>
<p>making sure it's using the same password as in lemmy.hjson</p>
<ul>
<li>lemmy=# \password</li>
</ul>
<p>VkNyXOFMCgb0sGjraJUz</p>
<pre><code>root@localhost:/home/hmks-apps/lemmy/hyperdata.it# docker ps -a
CONTAINER ID   IMAGE                        COMMAND                  CREATED      STATUS      PORTS                                                 NAMES
e519719e228e   nginx:1-alpine               &quot;/docker-entrypoint.…&quot;   2 days ago   Up 2 days   80/tcp, 0.0.0.0:20140-&gt;8536/tcp, :::20140-&gt;8536/tcp   hyperdatait_proxy_1
58f4af628105   dessalines/lemmy-ui:0.18.4   &quot;docker-entrypoint.s…&quot;   2 days ago   Up 2 days   1234/tcp                                              hyperdatait_lemmy-ui_1
9da7a413d90b   dessalines/lemmy:0.18.4      &quot;/app/lemmy&quot;             2 days ago   Up 2 days                                                         hyperdatait_lemmy_1
3394683cf319   postgres:15-alpine           &quot;docker-entrypoint.s…&quot;   2 days ago   Up 2 days   5432/tcp                                              hyperdatait_postgres_1
3792edf55801   asonix/pictrs:0.4.0          &quot;/sbin/tini -- /usr/…&quot;   2 days ago   Up 2 days   6669/tcp, 8080/tcp                                    hyperdatait_pictrs_1
157491f6495f   mwader/postfix-relay         &quot;/root/run&quot;              2 days ago   Up 2 days   25/tcp
</code></pre>
<p>ew, nginx &amp; posgres</p>
<p>docker stop e519719e228e (nginx)
docker restart 3394683cf319
docker restart 3792edf55801
docker restart 157491f6495f
docker restart 9da7a413d90b
docker restart 58f4af628105</p>
<p>no change</p>
<p>systemctl stop nginx
docker start e519719e228e</p>
<p>slight change</p>
<p>https://lemmy.hyperdata.it/
-&gt;
http://lemmy.hyperdata.it/</p>
<p>503 Service Unavailable</p>
<p>that's a change. Next need to check the logs. But enough for today.</p>
&nbsp;
        <!-- a class="more" href="/blog/lemmy/">...</a -->
    </p>
    <!--
<p class="summary">
https://github.com/LemmyNet recommends Ansible I opted for the full version - pipx install --include-deps ansible ew , initial bits painful, found the docs confusing, maybe assume&nbsp;<a class="more" href="/blog/lemmy/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/lemmy/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-02/">llama_index SPARQL Notes 02</a></h2>
    <p class="meta">Published on 2023-08-28 by <b>@danja</b></p>

    <p class="content">
        <p><strong>Aaargh! OpenAI API credit $0.21, and I won't have any money to top it up for another week or so</strong></p>
<p><em>What doesn't need the API?</em></p>
<p><strong>FOR TEMP CHANGES, UNMODIFIED FILES ARE IN ../original</strong>
<em>(I should probably make a branch in git, but then I'm likely to forget...)</em></p>
<p>My attention's been skipping around, spent a lot of time trying to engage with ChatGPT. There are bits of prompts I tried in <a href="/blog/llama-sparql-01">llama_index SPARQL Notes 01</a>.</p>
<p>Time to get back to the code proper (continuing from <a href="/blog/llama-sparql-00">llama_index SPARQL Notes 00</a>).</p>
<p>I've roughed out the shape of RDF I <em>think</em> I need :</p>
<pre><code># Simple Entity-Relation

@base &lt;http://purl.org/stuff/data&gt; .
@prefix er: &lt;http://purl.org/stuff/er&gt; .

&lt;#T123&gt; a er:Triplet ;
er:id &quot;#T123&quot; ;
er:subject &lt;#E123&gt; ;
er:property &lt;#R456&gt; ;
er:object &lt;#E567&gt; .

&lt;#E123&gt; a er:Entity ;
er:value &quot;one&quot; .

&lt;#R456&gt; a er:Relationship ;
er:value &quot;two&quot; .

&lt;#E567&gt; a er:Entity ;
er:value &quot;three&quot; .
</code></pre>
<p>But before writing the SPARQL I want to go back to <code>nebulagraph.py</code>, add some logging calls to see what it's <em>actually</em> passing around. Then go back to the tests, then forward...</p>
<p><strong>$0.21 mode</strong></p>
<p>Is there still data in my local NebulaGraph? I could populate a SPARQL store with that.</p>
<ul>
<li>
<p>sudo /usr/local/nebula/scripts/nebula.service restart all</p>
</li>
<li>
<p>./nebula-console -addr 127.0.0.1 -port 9669 -u root -p password</p>
</li>
</ul>
<p>wait, there's the GUI, NebulaGraph Studio -</p>
<p>http://localhost:7001/login</p>
<pre><code>USE guardians;

-- Fetch 10 vertices with the 'entity' tag
MATCH (v:entity)
RETURN v
LIMIT 10;
</code></pre>
<p>Yay!</p>
<p>One results column labelled v</p>
<pre><code>(&quot;$118.4 million&quot; :entity{name: &quot;$118.4 million&quot;})
...
</code></pre>
<pre><code>-- Fetch 10 edges with the 'relationship' type
MATCH (src:entity)-[e:relationship]-&gt;(dst:entity)
RETURN src, e, dst
LIMIT 10;
</code></pre>
<p>Results table column labels are src, e, dst</p>
<pre><code>(&quot;production on Vol.3&quot; :entity{name: &quot;production on Vol.3&quot;})	[:relationship &quot;production on Vol.3&quot;-&gt;&quot;February 2021&quot; @-8998665471782897487 {relationship: &quot;was put on hold until&quot;}]	(&quot;February 2021&quot; :entity{name: &quot;February 2021&quot;})
</code></pre>
<hr />
<p>Ok, enough for today.</p>
<p><a href="/blog/llama-sparql-03">Tomorrow</a>)</p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-02/">...</a -->
    </p>
    <!--
<p class="summary">
Aaargh! OpenAI API credit $0.21, and I won't have any money to top it up for another week or so What doesn't need the API?&nbsp;<a class="more" href="/blog/llama-sparql-02/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-02/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-01/">llama_index SPARQL Notes 01</a></h2>
    <p class="meta">Published on 2023-08-28 by <b>@danja</b></p>

    <p class="content">
        <p><strong>FOR TEMP CHANGES, UNMODIFIED FILES ARE IN ../original</strong></p>
<p>Today's task : as yesterday.</p>
<p>It's occurred to me that it would be helpful to look at the data that nebulagraph.py actually looks at - pop a few logging calls in there.</p>
<p>(Maybe also probe - https://github.com/vesoft-inc/nebula-python )</p>
<p>Before that, need to have python looking at my llama_index tree. PYTHON_PATH is empty so -</p>
<ul>
<li>python</li>
</ul>
<pre><code>&gt;&gt;&gt;import sys
&gt;&gt;&gt; print(sys.path)
&gt;&gt;&gt; ['', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '/home/danny/.local/lib/python3.11/site-packages', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.11/dist-packages']
</code></pre>
<p>Ok, found it at :</p>
<pre><code>~/.local/lib/python3.11/site-packages/llama_index
</code></pre>
<p>Hmm, which of Wey Gu's demos is the most minimal that uses NebulaGraph?</p>
<p>Custom instructions</p>
<pre><code>Act as a expert in Python and graph data structures, in particular the RDF model and SPARQL. Be prepared for questions relating to Large Language Models, Retrieval-Augmented Generation and the llama_index libraries. Follow best practices everywhere, eg. including short comments as necessary in code. Outside of code, keep all responses and descriptions very concise and matter-of-fact. Whenever you think it's possible I have further information or code files to upload that will help in the tasks, please ask.
My name is Danny.
</code></pre>
<p>~~Act as a expert in Python and graph data structures as implemented in NebulaGraph and RDF and SPARQL. ~~</p>
<pre><code>Existing code in llama_index includes communications to a NebulaGraph database via the nebula-python library. The goal for us today is to develop code in a file sparql.py having the same functionality as nebulagraph.py, but instead of NebulaGraph will connect to a SPARQL store via the sparqlwrapper library from RDFLib. There are several subtasks to do first, which I will describe after uploading some relevant code.

Here a zip of llama_index/llama_index/graph_stores

</code></pre>
<blockquote>
<p>Before writing Python, we will look at the data model. The following are the nGQL statements used to prepare the database for for nebulagraph.py. How would this an equilent schema be expressed in RDF, and what would an example of instance data look like?</p>
</blockquote>
<pre><code>CREATE SPACE guardians(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);
:sleep 10;
USE guardians;
CREATE TAG entity(name string);
CREATE EDGE relationship(relationship string);
:sleep 10;
CREATE TAG INDEX entity_index ON entity(name(256));
</code></pre>
<p>ChatGPT returns :</p>
<blockquote>
<p>In Nebula Graph, you're defining a space guardians with vertex IDs as fixed-length strings. You also define a tag entity with a property name of type string, and an edge type relationship with a property relationship of type string. Finally, you create an index on the name property of the entity tag.</p>
</blockquote>
<pre><code>@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .
@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .
@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .
@prefix ex: &lt;http://example.org/&gt; .

# Define the Entity class

ex:Entity rdf:type rdfs:Class ;
rdfs:label &quot;Entity&quot; ;
rdfs:comment &quot;An entity with a name&quot; .

# Define the name property

ex:name rdf:type rdf:Property ;
rdfs:label &quot;name&quot; ;
rdfs:comment &quot;The name of the entity&quot; ;
rdfs:domain ex:Entity ;
rdfs:range xsd:string .

# Define the Relationship class

ex:Relationship rdf:type rdfs:Class ;
rdfs:label &quot;Relationship&quot; ;
rdfs:comment &quot;A relationship between entities&quot; .

# Define the relationship property

ex:relationship rdf:type rdf:Property ;
rdfs:label &quot;relationship&quot; ;
rdfs:comment &quot;The type of relationship&quot; ;
rdfs:domain ex:Relationship ;
rdfs:range xsd:string .

and

@prefix ex: &lt;http://example.org/&gt; .

# Entities

ex:Alice rdf:type ex:Entity ;
ex:name &quot;Alice&quot; .

ex:Bob rdf:type ex:Entity ;
ex:name &quot;Bob&quot; .

# Relationship

ex:Alice ex:relationship ex:Bob ;
rdf:type ex:Relationship ;
ex:relationship &quot;friend&quot; .

</code></pre>
<p>using existing files under llama_index/llama_index/graph_stores as a guide, in particular the interface defined</p>
<pre><code>
</code></pre>
<p>ex:Relationship rdf:type rdfs:Class ;
rdfs:label &quot;Relationship&quot; ;
rdfs:comment &quot;A relationship between entities&quot; .</p>
<hr />
<p>Ok, do it by hand ...</p>
<p><this> a er:Triplet ;
er:id &quot;123&quot; ;
er:subject &quot;one&quot; ;
er:property &quot;two&quot; ;
er:object &quot;three&quot; .</p>
<p>But what/where are the IDs needed?
ok, maybe better :</p>
<pre><code># Simple Entity-Relation
@base &lt;http://purl.org/stuff/data&gt; .
@prefix er: &lt;http://purl.org/stuff/er&gt; .

&lt;#T123&gt; a er:Triplet ;
er:id &quot;#T123&quot; ;
er:subject &lt;#E123&gt; ;
er:property &lt;#R456&gt; ;
er:object &lt;#E567&gt; .

&lt;#E123&gt; a er:Entity ;
er:value &quot;one&quot; .

&lt;#R456&gt; a er:Relationship ;
er:value &quot;two&quot; .

&lt;#E567&gt; a er:Entity ;
er:value &quot;three&quot; .
</code></pre>
<hr />
<p>RDFS something like -</p>
<pre><code>@prefix er: &lt;http://purl.org/stuff/er&gt; .

er:Entity a rdfs:Class ;
rdfs:label &quot;Entity&quot; ;
rdfs:comment &quot;An entity...&quot; .

er:Relationship a rdfs:Class ;
rdfs:label &quot;Relationship&quot; ;
rdfs:comment &quot;A relationship between entities&quot; .

er:Triplet a rdfs:Class ;
rdfs:label &quot;Triplet&quot; ;
rdfs:comment &quot;A 3-tuple expressing a relationship between entities&quot; .

er:subject a rdf:Property ;
rdfs:label &quot;subject&quot; .
er:subject rdfs:domain er:Entity .
er:subject rdfs:range er:Entity .

er:subject a rdf:Property ;
rdfs:label &quot;subject&quot; .

er:subject a rdf:Property ;
rdfs:label &quot;subject&quot; .

rdfs:comment &quot;An entity...&quot; .
</code></pre>
<p>Probably not needed.</p>
<p>Time to move onto another doc</p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-01/">...</a -->
    </p>
    <!--
<p class="summary">
FOR TEMP CHANGES, UNMODIFIED FILES ARE IN ../original Today's task : as yesterday. It's occurred to me that it would be helpful to look at&nbsp;<a class="more" href="/blog/llama-sparql-01/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-01/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/Graph-of-Thoughs-initial-thoughts/">Graph of Thoughts, initial thoughts</a></h2>
    <p class="meta">Published on 2023-08-27 by <b>@danja</b></p>

    <p class="content">
        <p><em>Work in progress, scrappy notes &amp; thoughts to pull together. What sprang to mind, not thought through, likely much rubbish.</em></p>
<p>So I finally got around to reading the recent <a href="https://arxiv.org/abs/2308.09687">Graph of Thoughts : Solving Elaborate Problems with Large Language Models</a> paper. <em>&quot;Finally&quot; in the sense of it only appeared at Arxiv just over a week or so ago, I printed a couple of days ago. Things are moving sooo fast...</em></p>
<p>I do need to re-read it a few more times, also check some of the refs, there are bound to be papers that address the bits mentioned below (several are graph-related).So, initial thoughts. First is <strong>meta</strong>, the most important, subsuming everything else: <strong>It's really well written!</strong>. Research only really becomes useful when it's communicated. The text is as plain English as you can get with such material. Loads of acronyms, but that's unavoidable. But where they are significant, they're expanded and explained. Only as much maths as necessary, lovely - so often in this field, complicated sums muddy the water. Lots of clear-enough diagrams. Content-wise : <strong>Strong Accept</strong>.</p>
<p>Regarding content, in no particular order :</p>
<p>There are really tasty chunks, I really like the general approach.</p>
<p>For starters, identification of concrete goals : <code>How best to aggregate thoughts to maximise accuracy and minimise cost?</code>.
Some of the terms used (I've no idea which originated here or elsewhere, is irrelevant), like <code>Graph of Operations, GoO</code> and <code>Graph Reasoning State, GRS </code> are great markers for particular concepts.
The metric <strong>Volume</strong> the authors provide looks like it could be <strong>incredibly useful</strong>. It's stated in a couple of places, the plain English version is :</p>
<p><code>We define volume - for a given thought t - as the number of preceding LLM thoughts that could have impacted t</code></p>
<p>The evaluation seems broad enough to be reliable, applied in a way that makes sense. The use cases are seriously uninspiring, but I'd say that adds weight to this thing having potential - I think it would do better on harder problem.</p>
<p>Frankly <strong>I am very surprised</strong> they got results as good as they did. Ok, I personally think approaches along these lines can offer huge benefits over current Tree-of-Thought etc techniques. But I've had given it another year or so of architecture trial and error before seeing any noticeable gain. One of the use cases is keyword counting - from what I've seen, ChatGPT's ability with arithmetic is below that of a 5-year old, only marginally above that of a certain former US president.</p>
<p>Description Logics as a generalization</p>
<p>is all quasi-procedural logic
I
things like applying tabl</p>
<p>https://en.wikipedia.org/wiki/Method_of_analytic_tableaux</p>
<p>IBIS</p>
<p>to ping
@DrIBIS @doriantaylor</p>
<p>https://web.archive.org/web/20030418021226/http://ideagraph.net/xmlns/ibis/</p>
<p>https://vocab.methodandstructure.com/ibis</p>
<p>I hadn't thought through how to do it (see this paper!), but the <em>Graph of Thoughts</em> notion was a very visible next step after <em>Chain...</em> and <em>Tree...</em>. I discussed it with ChatGPT <a href="https://twitter.com/danja/status/1671680152500322304">a little while ago</a>. This reinforced my feeling that it should be a productive avenue, so at the end of our conversation I asked ChatGPT for advertizing copy to promote it :</p>
<blockquote>
<p>&quot;Unleash the power of graph-of-thought in LLM dialogues! Represent ideas as nodes, relationships as edges, and explore a web of knowledge. Navigate non-linearly, uncover intricate connections, and foster context-aware discussions.&quot;</p>
</blockquote>
<p>https://www.siwei.io/en/posts/</p>
<p>Conceptual Maps (Sowa) - his site? Concept Maps, Semantic Web/Linked Data</p>
<p>Layer Cake (bis)!
LLM stack
https://medium.com/@brian_90925/llms-and-the-emerging-ml-tech-stack-6fa66ee4561a
https://outerbounds.com/blog/llm-infrastructure-stack/</p>
<p>WebLM? WebML? <strong>Intelligent Web</strong></p>
<p>Agents</p>
&nbsp;
        <!-- a class="more" href="/blog/Graph-of-Thoughs-initial-thoughts/">...</a -->
    </p>
    <!--
<p class="summary">
Work in progress, scrappy notes &amp; thoughts to pull together. What sprang to mind, not thought through, likely much rubbish. So I finally got around&nbsp;<a class="more" href="/blog/Graph-of-Thoughs-initial-thoughts/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/Graph-of-Thoughs-initial-thoughts/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/post-one/">Post One</a></h2>
    <p class="meta">Published on 2023-08-26 by <b>@danja</b></p>

    <p class="content">
        <h2>This is a test</h2>
<p>Let's see it it <em>works</em></p>
<p>Note to self : check <a href="https://tmug.github.io/makesite-demo/blog/">layoutof of original makesite</a></p>
<p>hmm...</p>
&nbsp;
        <!-- a class="more" href="/blog/post-one/">...</a -->
    </p>
    <!--
<p class="summary">
This is a test Let's see it it works Note to self : check layoutof of original makesite hmm...&nbsp;<a class="more" href="/blog/post-one/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/post-one/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/llama-sparql-00/">llama_index SPARQL Notes 00</a></h2>
    <p class="meta">Published on 2018-08-27 by <b>@danja</b></p>

    <p class="content">
        <blockquote>
<p>This is a continuation of notes from <a href="https://github.com/danja/nlp/tree/main/GraphRAG">GraphRAG</a>. I'm currently writing a SPARQL connector for llama_index, and jotting notes as I go along. My Wordpress install recently broke, but because a SPARQL-backed blog engine was on my TODO list I let it ride. But it occurred to me that an easy stopgap would be to use a minimal static blog/site builder as an interim fix (makesite.py fit the bill), use it for the GraphRAG notes too. <strong>Nice layout with bells &amp; whistles to follow!</strong></p>
</blockquote>
<h3>Today</h3>
<p>Implementing a naive SPARQL connector, just enough to replicate the functional of Wey Gu's original demo with a SPARQL store rather than NebulaGraph.</p>
<p><em>I've read the books, but still my inclination on something like this would usually be to go straight to the implementation, only making tests when it (predictably) doesn't work. But my Python is weak and this codebase is new to me, so test-driven it is.</em></p>
<p>There don't appear to be any tests around the graph stores yet, so start against existing implementations, so, to build :</p>
<ol>
<li><code>llama_index/tests/graph_stores/test_simple.py</code></li>
<li><code>llama_index/tests/graph_stores/test_nebulagraph.py</code> - see how far I get, I probably won't understand what the helpers do, Wey Gu should be happy to improve</li>
<li><code>llama_index/tests/graph_stores/test_sparql.py</code></li>
<li><code>llama_index/graph_stores/sparql.py</code></li>
</ol>
<p>for reference :</p>
<ul>
<li>
<p><code>llama_index/graph_stores/types.py</code> - graph store interface <strong>vital ref</strong></p>
</li>
<li>
<p><code>llama_index/graph_stores/simple.py</code> - minimal graph store (in-memory dictionary)</p>
</li>
<li>
<p><code>llama_index/graph_stores/nebulagraph.py</code> - NebularGraph connector</p>
</li>
<li>
<p><code>llama_index/tests/vector_stores/test_cassandra.py</code> - related test implementation</p>
</li>
<li>
<p><code>llama_index/tests/vector_stores/test_postgres.py</code> - related test implementation</p>
</li>
<li>
<p><code>/llama_index/docs/examples/index_structs/knowledge_graph/nebulagraph_draw.html</code> etc</p>
</li>
</ul>
<p><strong>Trying existing tests</strong></p>
<p><code>pytest tests</code></p>
<p>missing dependency -</p>
<ul>
<li>pip install tree_sitter_languages</li>
</ul>
<p>try again, 4 FAILED, all from what I roughed out yesterday :)</p>
<p>5 ERROR, eg.</p>
<p>ERROR tests/llm_predictor/vellum/test_predictor.py::test_predict__basic - ModuleNotFoundError: No module named 'vellum'</p>
<p>dependency?</p>
<ul>
<li>pip install vellum</li>
</ul>
<p>9 failed, 247 passed, 79 skipped, 31 warnings in 2.75s</p>
<p>not-me failures around vellum</p>
<p>FAILED tests/llm_predictor/vellum/test_prompt_registry.py::test_from_prompt__new - ModuleNotFoundError: No module named 'vellum.core'</p>
<p>https://pypi.org/search/?q=vellum</p>
<p>try -</p>
<ul>
<li>pip install vellum-ai</li>
</ul>
<p>Lucky! 4 failed, 252 passed, 79 skipped, 31 warnings in 3.40s</p>
<p>Those 4 are my rubbish.</p>
<p>How to run individual test files? https://stackoverflow.com/questions/36456920/specify-which-pytest-tests-to-run-from-a-file</p>
<p>collected 0 items</p>
<p>test naming conventions https://stackoverflow.com/questions/37353960/why-pytest-is-not-collecting-tests-collected-0-items</p>
<p>Ooops - I used the wrong path.</p>
<ul>
<li>pytest tests/graph_stores/</li>
</ul>
<p>5 failed, 1 passed in 0.25s</p>
<ul>
<li>pytest tests/graph_stores/test_simple.py</li>
</ul>
<p>1 failed in 0.17s</p>
<p>I'd see the annotation <code>@pytest.fixture</code> elsewhere, but for pytest the test_naming was what it needed :</p>
<pre><code>def test_one_false():
    assert 1 == 0
</code></pre>
<p>ok, time to actually write code...</p>
<h3>Ask the assistant first</h3>
<p>I hadn't really explored ChatGPT's Code Interpreter. Had seen that you could upload source files, best as a zip.</p>
<p>So I thought, see how far it gets with <code>llama_index/graph_stores/</code></p>
&nbsp;
        <!-- a class="more" href="/blog/llama-sparql-00/">...</a -->
    </p>
    <!--
<p class="summary">
This is a continuation of notes from GraphRAG . I'm currently writing a SPARQL connector for llama_index, and jotting notes as I go along. My&nbsp;<a class="more" href="/blog/llama-sparql-00/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/llama-sparql-00/">Read More</a>
</div>
-->
</article><article>
    <h2><a href="/blog/template/">Post Two</a></h2>
    <p class="meta">Published on 2001-01-01 by <b>@danja</b></p>

    <p class="content">
        <h2>This is a test 2</h2>
<p>Let's see it it <em>works</em></p>
<p>Check <a href="https://tmug.github.io/makesite-demo/blog/">layoutof of original makesite</a></p>
&nbsp;
        <!-- a class="more" href="/blog/template/">...</a -->
    </p>
    <!--
<p class="summary">
This is a test 2 Let's see it it works Check layoutof of original makesite&nbsp;<a class="more" href="/blog/template/">...</a>
</p> mmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
-->

    <hr />

    <!--
<div>
<a class="more" href="/blog/template/">Read More</a>
</div>
-->
</article>
<section>
<a class="rss" href="/blog/rss.xml">RSS</a>
</section>

    </main>

    <footer>
        <section>
            <p>&copy; 2023 Danny Ayers, CC Attribution/MIT License</p>
            <p>Made with <a href="https://github.com/sunainapai">makesite</a></p>
        </section>
    </footer>

</body>

</html>